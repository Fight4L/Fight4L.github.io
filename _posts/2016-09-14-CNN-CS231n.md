---
layout: post
title: "CNN CS231n"
date: 2016-09-14 11:02
author: Liu
category: Computer Vision
tags: UTS Sydney CV
finished: true
---

> 老师提供的阅读材，上周就应该看完，但还是没看，这周需要看完然后看两篇FNN的论文并做一个report。 材料来自[CS231n](http://cs231n.github.io/convolutional-networks/)


# CNN

卷积神经网络即 Convolutional Neural Networks(CNNs / ConvNets)

CNN与普通的神经网络类似

  - 都由可学习权重(weights)和偏差(biases)的神经元(neurons)组成
  - 每个神经元接受一些输入，进行点积或其他非线性计算。
  - 整个网络表现为一个微积分函数
  - 从原始图像的一端的像素到另一端的class scores。
  - 在最后一层依然有一个损失函数(loss function)

卷积神经网络结构假设输入为图像，对某些属性进行编码。这使得 forward function 更有效的实现并且大量减少网络中的参数。

## Architecture Overview

常规神经网络(_Regular Neural Nets_)接收一个输入，通过一系列隐藏层(_hidden layers_)来转换输入。每个隐藏层由一组神经元组成，每个神经元与上一层的所有神经元完全连接，并且每层神经元之间完全独立。最后一层叫作输出层(output layer)，在分类问题中代表分类结果。

_Regular Neural Nets don’t scale well to full images._ 如果一个图像是32*32*3(32 wide, 32 high, 3 color channels)，那么第一个隐藏层的一个全连接的神经元将有32*32*3=3072个参数，如果是200*200*3的图像，就是200*200*3=120,000个参数。参数太多。

_3D volimes of neurons_ CNN利用输入为图像限定结构。ConvNet每层的神经元排列为3维：width, height, depth。每层的神经元只连接上一层的少量区域，而不是全连接的方式。最终的输出层将降维成一个分类结果的向量。
![CNN](/img/blog/20160914/CNN.png);

> A ConvNet is made up of Layers. Every Layer has a simple API: It transforms an input 3D volume to an output 3D volume with some differentiable function that may or may not have parameters.

## Layers used to build ConvNets

__A simple ConvNet__ is a sequence of layers, and every layer of a ConvNet transforms one volume of activations to another through a differentiable function.

Three main types of layers to build ConvNet architectures: __Convolutional Layer__, __Pooling Layer__, and __Fully-Connected Layer__ (exactly as seen in regular Neural Networks).

以CIDFAR-10举例，建立一个简单的[INPUT - CONV - RELU - POOL - FC]的ConvNet来分类。

  - _INPUT:_ 输入图像为[32*32*3],分别代表图像宽32，高32，RGB。
  - _CONV:_ 卷积层计算连接输入层局部区域的输出神经元，每个神经元将其权值与区域点乘(dot product)。如果我们使用的过滤器为12，那么结果为[32*32*12]。
  - _RELU:_ 这一层将使用元素激活函数(elementwise activation function),比如`max(0,x)`阈值为0。并不改变图像的大小。
  - _POOL:_ 采样层/池化层在空间维度(width,heigh)进行降采样，结果可能为[16*16*12]
  - _FC:_ (i.e. Fully-Connected)全连接层计算分类结果，结果为一个[1*1*10]的向量，这10个数字指向分类结果比如说CIFAR-10的10类图片。这一层的每个神经元与上一层的所有神经元连接。

ConvNets一层一层的将原始图像转换为最终分类结果。在CONV/FC层的函数不仅激活输出层，而且带有参数(the weights and biases of the neurons). 这些参数可以使用梯度下降来选定从而使训练结果更好。

综上：

  - A ConvNet architecture is in the simplest case a list of Layers that transform the image volume into an output volume (e.g. holding the class scores)
  - There are a few distinct types of Layers (e.g. CONV/FC/RELU/POOL are by far the most popular)
  - Each Layer accepts an input 3D volume and transforms it to an output 3D volume through a differentiable function
  - Each Layer may or may not have parameters (e.g. CONV/FC do, RELU/POOL don’t)
  - Each Layer may or may not have additional hyperparameters (e.g. CONV/FC/POOL do, RELU doesn’t)
